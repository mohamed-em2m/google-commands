{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bc6d554-189e-4b74-bf78-69ae659704bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy ,SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tensorflow.keras.losses import MeanSquaredLogarithmicError\n",
    "from tensorflow import keras as k\n",
    "import numpy as np\n",
    "# for building linear regression models and preparing data\n",
    "from sklearn.linear_model import LinearRegression ,LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from xgboost import *\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f4d658e-50cc-4e1e-a444-403acbda02fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    #for filename in filenames:\n",
    "        #print(os.path.join(dirname, filename))\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "#from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten,Dense,Dropout,BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from tensorflow.keras.applications import VGG16, InceptionResNetV2\n",
    "from keras import regularizers\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "import datetime\n",
    "labels={ 0:'angry',\n",
    " 1:'disgust',\n",
    " 2:'fear',\n",
    " 3:'happy',\n",
    " 4:'neutral',\n",
    " 5:'sad',\n",
    "6 :'surprise'}\n",
    "colors={ 0:(0,0,255),\n",
    " 1:(100,0,100),\n",
    " 2:(200,50,123),\n",
    " 3:(0,255,255),\n",
    " 4:(0,255,0),\n",
    " 5:(255,255,0),\n",
    "6 :(255,0,0)}\n",
    "import numpy as np\n",
    "def reshape(img):\n",
    "    img = cv2.resize(img, (48, 48))  # Resize to the input shape of the model\n",
    "    print(img.shape)\n",
    "    img = img.reshape( 1,48, 48, 1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d46433d-7cae-45fa-b024-629c509399c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# use dlib algorizm to detect faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a0ac87-624b-4505-b2d4-462b47f3ba13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dlib import get_frontal_face_detector\n",
    "import numpy as np\n",
    "hog=get_frontal_face_detector()\n",
    "force=cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "model=k.models.load_model('fernet (1).h5')\n",
    "\n",
    "vid=cv2.VideoCapture(\"Downloads/y2mate.com - Example of Human Facial Expressions  Emotions_360p.mp4\")# if you would use camera put zero as a path\n",
    "write=cv2.VideoWriter('emotion2.mp4',force,25,(int(vid.get(3)),int(vid.get(4))))\n",
    "num2=0\n",
    "while True:\n",
    "    rec,frame=vid.read() \n",
    "    print(rec)\n",
    "    if (rec):\n",
    "        img=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY) \n",
    "        for block in hog(img,1,):\n",
    "            img2=reshape(img[block.top():block.bottom(),block.left():block.right()])\n",
    "            num=np.argmax(model.predict(img2),axis=1)[0]\n",
    "            mode=labels[num]\n",
    "            cv2.rectangle(frame,(int(block.left()),int(block.top())),(int(block.right()),int(block.bottom())),colors[num],3)\n",
    "            cv2.putText(frame,str(mode),(int(block.left()),int(block.top()-15)),cv2.FONT_ITALIC,1,colors[num],3)\n",
    "        #cv2.imshow(\"wind\",frame)\n",
    "        write.write(frame)\n",
    "        #if (cv2.waitKey(1)==27):\n",
    "         #   break\n",
    "        num2+=1\n",
    "        print(num2)\n",
    "write.release()            \n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9231f03-702f-4381-86c6-509a4be78bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    #for filename in filenames:\n",
    "        #print(os.path.join(dirname, filename))\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "#from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "import keras as k\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten,Dense,Dropout,BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, InceptionResNetV2\n",
    "from keras import regularizers\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "import datetime\n",
    "labels={ 0:'angry',\n",
    " 1:'disgust',\n",
    " 2:'fear',\n",
    " 3:'happy',\n",
    " 4:'neutral',\n",
    " 5:'sad',\n",
    "6 :'surprise'}\n",
    "colors={ 0:(0,0,255),\n",
    " 1:(100,0,100),\n",
    " 2:(200,50,123),\n",
    " 3:(0,255,255),\n",
    " 4:(0,255,0),\n",
    " 5:(255,255,0),\n",
    "6 :(255,0,0)}\n",
    "import numpy as np\n",
    "def reshape(img):\n",
    "    img = cv2.resize(img, (48, 48))  # Resize to the input shape of the model\n",
    "    print(img.shape)\n",
    "    img = img.reshape( 1,48, 48, 1)\n",
    "    return img\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e530b6af-ac1a-4b58-80eb-08f3a4f77fb3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# detect emotion of face in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f19328f8-ef9a-4d9f-bacf-f8689c9e7905",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(410, 760) [(181, 54) (284, 158)] 54 158 181 284 (104, 103)\n",
      "(48, 48)\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "(410, 760) [(31, 65) (135, 169)] 65 169 31 135 (104, 104)\n",
      "(48, 48)\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "(410, 760) [(492, 261) (595, 365)] 261 365 492 595 (104, 103)\n",
      "(48, 48)\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "(410, 760) [(342, 65) (446, 169)] 65 169 342 446 (104, 104)\n",
      "(48, 48)\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "(410, 760) [(492, 54) (595, 158)] 54 158 492 595 (104, 103)\n",
      "(48, 48)\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "(410, 760) [(641, 261) (745, 365)] 261 365 641 745 (104, 104)\n",
      "(48, 48)\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "(410, 760) [(630, 65) (734, 169)] 65 169 630 734 (104, 104)\n",
      "(48, 48)\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "(410, 760) [(31, 273) (135, 377)] 273 377 31 135 (104, 104)\n",
      "(48, 48)\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "(410, 760) [(342, 250) (446, 353)] 250 353 342 446 (103, 104)\n",
      "(48, 48)\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "(410, 760) [(181, 273) (284, 377)] 273 377 181 284 (104, 103)\n",
      "(48, 48)\n",
      "1/1 [==============================] - 0s 53ms/step\n"
     ]
    }
   ],
   "source": [
    "        from dlib import get_frontal_face_detector\n",
    "\n",
    "        hog=get_frontal_face_detector()\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "        model=k.models.load_model('fernet (1).h5')\n",
    "        cv2.namedWindow(\"wind\",cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow(\"wind\",1000,1000)\n",
    "        frame=cv2.imread(\"Pictures/1_EeGMTlW4HL-ZAgPKnv1R8g.jpg\")\n",
    "        img=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY) \n",
    "        for block in hog(img):\n",
    "          print(img.shape,block,block.top(),block.bottom(),block.left(),block.right(),img[block.top():block.bottom(),block.left():block.right()].shape)\n",
    "          if(img[block.top():block.bottom(),block.left():block.right()].shape[0]>0):\n",
    "            img2=reshape(img[block.top()-10:block.bottom(),block.left():block.right()])\n",
    "            num=np.argmax(model.predict(img2),axis=1)[0]\n",
    "            mode=labels[num]\n",
    "            frame=cv2.rectangle(frame,(int(block.left()),int(block.top())),(int(block.right()),int(block.bottom())),colors[num],3)\n",
    "            frame=cv2.putText(frame,str(mode),(int(block.left()),int(block.top())),cv2.FONT_ITALIC,1,colors[num],3)\n",
    "        cv2.imshow(\"wind\",frame)\n",
    "        cv2.waitKey()\n",
    "        \n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933126be-49d4-417e-b077-3b29100d1c08",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# use cascade classifier to detect faces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07e0330-d3d1-4540-a352-df3705bbcdd1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m=\u001b[39mk\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfernet (1).h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m vid\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;66;03m# if you would put a vide revmove 0 and put the path\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mvid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp://192.168.1.3:8080/video\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m cv2\u001b[38;5;241m.\u001b[39mnamedWindow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwind\u001b[39m\u001b[38;5;124m\"\u001b[39m,cv2\u001b[38;5;241m.\u001b[39mWINDOW_NORMAL)\n\u001b[0;32m      6\u001b[0m cv2\u001b[38;5;241m.\u001b[39mresizeWindow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwind\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m1000\u001b[39m,\u001b[38;5;241m1000\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "model=k.models.load_model('fernet (1).h5')\n",
    "vid=cv2.VideoCapture(0)# if you would put a vide revmove 0 and put the path\n",
    "cv2.namedWindow(\"wind\",cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"wind\",1000,1000)\n",
    "while True:\n",
    "    rec,frame=vid.read()  \n",
    "    print(rec)\n",
    "    if (rec):\n",
    "        img=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY) \n",
    "        faces=face_cascade.detectMultiScale(img,scaleFactor=1.3, minNeighbors=5)\n",
    "        for (x,y,w,h) in faces:\n",
    "         try: #print(block)\n",
    "            img2=reshape(img[x:x+w+1,y:y+h+1])\n",
    "            num=np.argmax(model.predict(img2),axis=1)[0]\n",
    "            mode=labels[num]\n",
    "            cv2.rectangle(frame,(int(x),int(y)),(int(x+w),int(y+h)),colors[num],3)\n",
    "            cv2.putText(frame,str(mode),(int(x),int(y-15)),cv2.FONT_ITALIC,1,colors[num],3)\n",
    "            \"\"\" \n",
    "            img=reshape(img[block.top():block.bottom(),block.left():block.right()])\n",
    "            num=np.argmax(model.predict(img),axis=1)[0]\n",
    "            mode=labels[num]\n",
    "            cv2.rectangle(frame,(int(block.left()),int(block.top())),(int(block.right()),int(block.bottom())),colors[num],3)\n",
    "            cv2.putText(frame,str(mode),(int(block.left()),int(block.top()-15)),cv2.FONT_ITALIC,1,colors[num],3)\"\"\"\n",
    "            cv2.imshow(\"wind\",frame)\n",
    "            if (cv2.waitKey(1)==27):\n",
    "               break\n",
    "         except:\n",
    "            cv2.imshow(\"wind\",np.zeros(shape=(1000,1000)))\n",
    "            if (cv2.waitKey(1)==27):\n",
    "               break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3c1fd0-1a41-42c3-91ff-99722b302e66",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# using mtcnn alghorizm to detect faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a197df56-6a49-4c27-998b-6174813f31c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mtcnn import MTCNN\n",
    "import numpy as np\n",
    "hog=MTCNN ()\n",
    "face_cascade = MTCNN ()\n",
    "\n",
    "model=k.models.load_model('fernet (1).h5')\n",
    "vid=cv2.VideoCapture(0)# if you would put a vide revmove 0 and put the path\n",
    "while True:\n",
    "    rec,frame=vid.read()  \n",
    "    print(rec)\n",
    "    if (rec):\n",
    "        img=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB) \n",
    "        faces=face_cascade.detect_faces(img)\n",
    "        for face in faces:\n",
    "          #print(block)\n",
    "          img=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "          (x,y,w,h)=face['box']\n",
    "          if(len(img[x:x+w,y:y+h])>0):\n",
    "            img2=reshape(img[x:x+w,y:y+h])\n",
    "            num=np.argmax(model.predict(img2),axis=1)[0]\n",
    "            mode=labels[num]\n",
    "            cv2.rectangle(frame,(int(x),int(y)),(int(x+w),int(y+h)),colors[num],3)\n",
    "            cv2.putText(frame,str(mode),(int(x),int(y-15)),cv2.FONT_ITALIC,1,colors[num],3)\n",
    "            \"\"\" \n",
    "            img=reshape(img[block.top():block.bottom(),block.left():block.right()])\n",
    "            num=np.argmax(model.predict(img),axis=1)[0]\n",
    "            mode=labels[num]\n",
    "            cv2.rectangle(frame,(int(block.left()),int(block.top())),(int(block.right()),int(block.bottom())),colors[num],3)\n",
    "            cv2.putText(frame,str(mode),(int(block.left()),int(block.top()-15)),cv2.FONT_ITALIC,1,colors[num],3)\"\"\"\n",
    "        cv2.imshow(\"wind\",frame)\n",
    "        if (cv2.waitKey(1)==27):\n",
    "            break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c634072-9d67-4206-913b-a13088f613ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mtcnn\n",
      "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
      "     ---------------------------------------- 2.3/2.3 MB 370.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: opencv-python>=4.1.0 in d:\\anaconda\\lib\\site-packages (from mtcnn) (4.7.0.72)\n",
      "Requirement already satisfied: keras>=2.0.0 in d:\\anaconda\\lib\\site-packages (from mtcnn) (2.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\anaconda\\lib\\site-packages (from opencv-python>=4.1.0->mtcnn) (1.22.4)\n",
      "Installing collected packages: mtcnn\n",
      "Successfully installed mtcnn-0.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\anaconda\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install mtcnn "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
